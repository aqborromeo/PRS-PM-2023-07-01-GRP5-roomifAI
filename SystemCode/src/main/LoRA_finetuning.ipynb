{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "slgjeYgd6pWp"
      },
      "source": [
        "# **Stable Diffusion - LoRA**"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "tTVqCAgSmie4"
      },
      "source": [
        "# I. Installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "cellView": "form",
        "id": "_u3q60di584x"
      },
      "outputs": [],
      "source": [
        "# @title ## Install Dependencies\n",
        "import os\n",
        "import zipfile\n",
        "import shutil\n",
        "import time\n",
        "from subprocess import getoutput\n",
        "from IPython.utils import capture\n",
        "from run_training import train_model"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "yHNbl3O_NSS0"
      },
      "source": [
        "# Model Training \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "cellView": "form",
        "id": "H_Q23fUEJhnC"
      },
      "outputs": [],
      "source": [
        "# @title ## Model Config\n",
        "# Change the key to:\n",
        "# - living\n",
        "# - bedroom\n",
        "# - dining\n",
        "import json\n",
        "\n",
        "# Uncomment the config file lines for the respective rooms\n",
        "config_path = './train/LoRA/config/living-config.json'\n",
        "# config_path = './train/LoRA/config/bedroom-config.json'\n",
        "# config_path = './train/LoRA/config/dining-config.json'\n",
        "\n",
        "with open(config_path) as json_file:\n",
        "    configs = json.load(json_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "cellView": "form",
        "id": "p_SHtbFwHVl1"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">19:40:21-934757 </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Start training LoRA Standard <span style=\"color: #808000; text-decoration-color: #808000\">...</span>                                                          \n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[2;36m19:40:21-934757\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Start training LoRA Standard \u001b[33m...\u001b[0m                                                          \n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">19:40:21-939779 </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Checking for duplicate image filenames in training data directory<span style=\"color: #808000; text-decoration-color: #808000\">...</span>                      \n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[2;36m19:40:21-939779\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Checking for duplicate image filenames in training data directory\u001b[33m...\u001b[0m                      \n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">19:40:21-945545 </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Valid image folder names found in: .<span style=\"color: #800080; text-decoration-color: #800080\">/train/LoRA/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">train_data</span>                                \n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[2;36m19:40:21-945545\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Valid image folder names found in: .\u001b[35m/train/LoRA/\u001b[0m\u001b[95mtrain_data\u001b[0m                                \n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">19:40:21-947761 </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Headless mode, skipping verification if model already exist<span style=\"color: #808000; text-decoration-color: #808000\">...</span> if model already exist it  \n",
              "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                </span>         will be overwritten<span style=\"color: #808000; text-decoration-color: #808000\">...</span>                                                                    \n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[2;36m19:40:21-947761\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Headless mode, skipping verification if model already exist\u001b[33m...\u001b[0m if model already exist it  \n",
              "\u001b[2;36m                \u001b[0m         will be overwritten\u001b[33m...\u001b[0m                                                                    \n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">19:40:21-950760 </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Folder 10_living: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">160</span> images found                                                        \n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[2;36m19:40:21-950760\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Folder 10_living: \u001b[1;36m160\u001b[0m images found                                                        \n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">19:40:21-952232 </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Folder 10_living: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1600</span> steps                                                              \n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[2;36m19:40:21-952232\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Folder 10_living: \u001b[1;36m1600\u001b[0m steps                                                              \n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">19:40:21-954239 </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Total steps: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1600</span>                                                                         \n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[2;36m19:40:21-954239\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Total steps: \u001b[1;36m1600\u001b[0m                                                                         \n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">19:40:21-955239 </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Train batch size: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>                                                                       \n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[2;36m19:40:21-955239\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Train batch size: \u001b[1;36m1\u001b[0m                                                                       \n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">19:40:21-956746 </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Gradient accumulation steps: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>                                                            \n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[2;36m19:40:21-956746\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Gradient accumulation steps: \u001b[1;36m4\u001b[0m                                                            \n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">19:40:21-958752 </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Epoch: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>                                                                                  \n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[2;36m19:40:21-958752\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Epoch: \u001b[1;36m1\u001b[0m                                                                                  \n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">19:40:21-959752 </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Regulatization factor: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>                                                                  \n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[2;36m19:40:21-959752\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Regulatization factor: \u001b[1;36m1\u001b[0m                                                                  \n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">19:40:21-961908 </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> max_train_steps <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1600</span> <span style=\"color: #800080; text-decoration-color: #800080\">/</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> <span style=\"color: #800080; text-decoration-color: #800080\">/</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span> * <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> * <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">)</span> = <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">400</span>                                              \n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[2;36m19:40:21-961908\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m max_train_steps \u001b[1m(\u001b[0m\u001b[1;36m1600\u001b[0m \u001b[35m/\u001b[0m \u001b[1;36m1\u001b[0m \u001b[35m/\u001b[0m \u001b[1;36m4\u001b[0m * \u001b[1;36m1\u001b[0m * \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m = \u001b[1;36m400\u001b[0m                                              \n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">19:40:21-963481 </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> stop_text_encoder_training = <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>                                                            \n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[2;36m19:40:21-963481\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m stop_text_encoder_training = \u001b[1;36m0\u001b[0m                                                            \n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">19:40:21-965996 </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> lr_warmup_steps = <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">40</span>                                                                      \n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[2;36m19:40:21-965996\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m lr_warmup_steps = \u001b[1;36m40\u001b[0m                                                                      \n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">19:40:21-968258 </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Saving training config to .<span style=\"color: #800080; text-decoration-color: #800080\">/train/LoRA/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">output</span>\\roomifai_living_20231024-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">194021.j</span>son<span style=\"color: #808000; text-decoration-color: #808000\">...</span>     \n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[2;36m19:40:21-968258\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Saving training config to .\u001b[35m/train/LoRA/\u001b[0m\u001b[95moutput\u001b[0m\\roomifai_living_20231024-\u001b[1;36m194021.j\u001b[0mson\u001b[33m...\u001b[0m     \n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">19:40:21-970975 </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> accelerate launch --<span style=\"color: #808000; text-decoration-color: #808000\">num_cpu_threads_per_process</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span> <span style=\"color: #008000; text-decoration-color: #008000\">\"./train_network.py\"</span> --enable_bucket    \n",
              "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                </span>         --<span style=\"color: #808000; text-decoration-color: #808000\">min_bucket_reso</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">256</span> --<span style=\"color: #808000; text-decoration-color: #808000\">max_bucket_reso</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2048</span>                                              \n",
              "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                </span>         --<span style=\"color: #808000; text-decoration-color: #808000\">pretrained_model_name_or_path</span>=<span style=\"color: #008000; text-decoration-color: #008000\">\"runwayml/stable-diffusion-v1-5\"</span>                          \n",
              "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                </span>         --<span style=\"color: #808000; text-decoration-color: #808000\">train_data_dir</span>=<span style=\"color: #008000; text-decoration-color: #008000\">\"./train/LoRA/train_data\"</span> --<span style=\"color: #808000; text-decoration-color: #808000\">resolution</span>=<span style=\"color: #008000; text-decoration-color: #008000\">\"512,512\"</span>                         \n",
              "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                </span>         --<span style=\"color: #808000; text-decoration-color: #808000\">output_dir</span>=<span style=\"color: #008000; text-decoration-color: #008000\">\"./train/LoRA/output\"</span> --<span style=\"color: #808000; text-decoration-color: #808000\">logging_dir</span>=<span style=\"color: #008000; text-decoration-color: #008000\">\"./train/LoRA/logs\"</span> --<span style=\"color: #808000; text-decoration-color: #808000\">network_alpha</span>=<span style=\"color: #008000; text-decoration-color: #008000\">\"1\"</span>  \n",
              "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                </span>         --<span style=\"color: #808000; text-decoration-color: #808000\">save_model_as</span>=<span style=\"color: #800080; text-decoration-color: #800080\">safetensors</span> --<span style=\"color: #808000; text-decoration-color: #808000\">network_module</span>=<span style=\"color: #800080; text-decoration-color: #800080\">networks</span>.lora --<span style=\"color: #808000; text-decoration-color: #808000\">text_encoder_lr</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5e-05</span>        \n",
              "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                </span>         --<span style=\"color: #808000; text-decoration-color: #808000\">unet_lr</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0001</span> --<span style=\"color: #808000; text-decoration-color: #808000\">network_dim</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span> --<span style=\"color: #808000; text-decoration-color: #808000\">gradient_accumulation_steps</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>                          \n",
              "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                </span>         --<span style=\"color: #808000; text-decoration-color: #808000\">output_name</span>=<span style=\"color: #008000; text-decoration-color: #008000\">\"roomifai_living\"</span> --<span style=\"color: #808000; text-decoration-color: #808000\">lr_scheduler_num_cycles</span>=<span style=\"color: #008000; text-decoration-color: #008000\">\"1\"</span> --no_half_vae               \n",
              "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                </span>         --<span style=\"color: #808000; text-decoration-color: #808000\">learning_rate</span>=<span style=\"color: #008000; text-decoration-color: #008000\">\"0.0001\"</span> --<span style=\"color: #808000; text-decoration-color: #808000\">lr_scheduler</span>=<span style=\"color: #008000; text-decoration-color: #008000\">\"cosine\"</span> --<span style=\"color: #808000; text-decoration-color: #808000\">lr_warmup_steps</span>=<span style=\"color: #008000; text-decoration-color: #008000\">\"40\"</span>                   \n",
              "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                </span>         --<span style=\"color: #808000; text-decoration-color: #808000\">train_batch_size</span>=<span style=\"color: #008000; text-decoration-color: #008000\">\"1\"</span> --<span style=\"color: #808000; text-decoration-color: #808000\">max_train_steps</span>=<span style=\"color: #008000; text-decoration-color: #008000\">\"400\"</span> --<span style=\"color: #808000; text-decoration-color: #808000\">save_every_n_epochs</span>=<span style=\"color: #008000; text-decoration-color: #008000\">\"1\"</span>                  \n",
              "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                </span>         --<span style=\"color: #808000; text-decoration-color: #808000\">mixed_precision</span>=<span style=\"color: #008000; text-decoration-color: #008000\">\"fp16\"</span> --<span style=\"color: #808000; text-decoration-color: #808000\">save_precision</span>=<span style=\"color: #008000; text-decoration-color: #008000\">\"fp16\"</span> --<span style=\"color: #808000; text-decoration-color: #808000\">caption_extension</span>=<span style=\"color: #008000; text-decoration-color: #008000\">\".txt\"</span>               \n",
              "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                </span>         --cache_latents --<span style=\"color: #808000; text-decoration-color: #808000\">optimizer_type</span>=<span style=\"color: #008000; text-decoration-color: #008000\">\"AdamW8bit\"</span> --<span style=\"color: #808000; text-decoration-color: #808000\">max_data_loader_n_workers</span>=<span style=\"color: #008000; text-decoration-color: #008000\">\"0\"</span>              \n",
              "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                </span>         --<span style=\"color: #808000; text-decoration-color: #808000\">bucket_reso_steps</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">64</span> --<span style=\"color: #808000; text-decoration-color: #808000\">save_every_n_steps</span>=<span style=\"color: #008000; text-decoration-color: #008000\">\"100\"</span> --bucket_no_upscale --<span style=\"color: #808000; text-decoration-color: #808000\">noise_offset</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span>  \n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[2;36m19:40:21-970975\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m accelerate launch --\u001b[33mnum_cpu_threads_per_process\u001b[0m=\u001b[1;36m2\u001b[0m \u001b[32m\"./train_network.py\"\u001b[0m --enable_bucket    \n",
              "\u001b[2;36m                \u001b[0m         --\u001b[33mmin_bucket_reso\u001b[0m=\u001b[1;36m256\u001b[0m --\u001b[33mmax_bucket_reso\u001b[0m=\u001b[1;36m2048\u001b[0m                                              \n",
              "\u001b[2;36m                \u001b[0m         --\u001b[33mpretrained_model_name_or_path\u001b[0m=\u001b[32m\"runwayml\u001b[0m\u001b[32m/stable-diffusion-v1-5\"\u001b[0m                          \n",
              "\u001b[2;36m                \u001b[0m         --\u001b[33mtrain_data_dir\u001b[0m=\u001b[32m\"./train/LoRA/train_data\"\u001b[0m --\u001b[33mresolution\u001b[0m=\u001b[32m\"512\u001b[0m\u001b[32m,512\"\u001b[0m                         \n",
              "\u001b[2;36m                \u001b[0m         --\u001b[33moutput_dir\u001b[0m=\u001b[32m\"./train/LoRA/output\"\u001b[0m --\u001b[33mlogging_dir\u001b[0m=\u001b[32m\"./train/LoRA/logs\"\u001b[0m --\u001b[33mnetwork_alpha\u001b[0m=\u001b[32m\"1\"\u001b[0m  \n",
              "\u001b[2;36m                \u001b[0m         --\u001b[33msave_model_as\u001b[0m=\u001b[35msafetensors\u001b[0m --\u001b[33mnetwork_module\u001b[0m=\u001b[35mnetworks\u001b[0m.lora --\u001b[33mtext_encoder_lr\u001b[0m=\u001b[1;36m5e\u001b[0m\u001b[1;36m-05\u001b[0m        \n",
              "\u001b[2;36m                \u001b[0m         --\u001b[33munet_lr\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0001\u001b[0m --\u001b[33mnetwork_dim\u001b[0m=\u001b[1;36m8\u001b[0m --\u001b[33mgradient_accumulation_steps\u001b[0m=\u001b[1;36m4\u001b[0m                          \n",
              "\u001b[2;36m                \u001b[0m         --\u001b[33moutput_name\u001b[0m=\u001b[32m\"roomifai_living\"\u001b[0m --\u001b[33mlr_scheduler_num_cycles\u001b[0m=\u001b[32m\"1\"\u001b[0m --no_half_vae               \n",
              "\u001b[2;36m                \u001b[0m         --\u001b[33mlearning_rate\u001b[0m=\u001b[32m\"0\u001b[0m\u001b[32m.0001\"\u001b[0m --\u001b[33mlr_scheduler\u001b[0m=\u001b[32m\"cosine\"\u001b[0m --\u001b[33mlr_warmup_steps\u001b[0m=\u001b[32m\"40\"\u001b[0m                   \n",
              "\u001b[2;36m                \u001b[0m         --\u001b[33mtrain_batch_size\u001b[0m=\u001b[32m\"1\"\u001b[0m --\u001b[33mmax_train_steps\u001b[0m=\u001b[32m\"400\"\u001b[0m --\u001b[33msave_every_n_epochs\u001b[0m=\u001b[32m\"1\"\u001b[0m                  \n",
              "\u001b[2;36m                \u001b[0m         --\u001b[33mmixed_precision\u001b[0m=\u001b[32m\"fp16\"\u001b[0m --\u001b[33msave_precision\u001b[0m=\u001b[32m\"fp16\"\u001b[0m --\u001b[33mcaption_extension\u001b[0m=\u001b[32m\".txt\"\u001b[0m               \n",
              "\u001b[2;36m                \u001b[0m         --cache_latents --\u001b[33moptimizer_type\u001b[0m=\u001b[32m\"AdamW8bit\"\u001b[0m --\u001b[33mmax_data_loader_n_workers\u001b[0m=\u001b[32m\"0\"\u001b[0m              \n",
              "\u001b[2;36m                \u001b[0m         --\u001b[33mbucket_reso_steps\u001b[0m=\u001b[1;36m64\u001b[0m --\u001b[33msave_every_n_steps\u001b[0m=\u001b[32m\"100\"\u001b[0m --bucket_no_upscale --\u001b[33mnoise_offset\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m  \n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#@title ## Start Training\n",
        "# Replace invalid config params\n",
        "if 'stop_text_encoder_training' in configs:\n",
        "    configs['stop_text_encoder_training_pct'] = configs.pop('stop_text_encoder_training')\n",
        "\n",
        "train_model(headless=True, print_only=False, **configs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[19:42:00] WARNING  The following values were not passed to       launch.py:895\n",
            "                    `accelerate launch` and had defaults used                  \n",
            "                    instead:                                                   \n",
            "                            `--num_processes` was set to a value               \n",
            "                    of `1`                                                     \n",
            "                            `--num_machines` was set to a value                \n",
            "                    of `1`                                                     \n",
            "                            `--mixed_precision` was set to a                   \n",
            "                    value of `'no'`                                            \n",
            "                            `--dynamo_backend` was set to a value              \n",
            "                    of `'no'`                                                  \n",
            "                    To avoid this warning pass in values for each              \n",
            "                    of the problematic parameters or run                       \n",
            "                    `accelerate config`.                                       \n",
            "prepare tokenizer\n",
            "Using DreamBooth method.\n",
            "prepare images.\n",
            "found directory train\\LoRA\\train_data\\10_living contains 160 image files\n",
            "1600 train images with repeating.\n",
            "0 reg images.\n",
            "no regularization images / 正則化画像が見つかりませんでした\n",
            "[Dataset 0]\n",
            "  batch_size: 1\n",
            "  resolution: (512, 512)\n",
            "  enable_bucket: True\n",
            "  min_bucket_reso: 256\n",
            "  max_bucket_reso: 2048\n",
            "  bucket_reso_steps: 64\n",
            "  bucket_no_upscale: True\n",
            "\n",
            "  [Subset 0 of Dataset 0]\n",
            "    image_dir: \"train\\LoRA\\train_data\\10_living\"\n",
            "    image_count: 160\n",
            "    num_repeats: 10\n",
            "    shuffle_caption: False\n",
            "    keep_tokens: 0\n",
            "    caption_dropout_rate: 0.0\n",
            "    caption_dropout_every_n_epoches: 0\n",
            "    caption_tag_dropout_rate: 0.0\n",
            "    caption_prefix: None\n",
            "    caption_suffix: None\n",
            "    color_aug: False\n",
            "    flip_aug: False\n",
            "    face_crop_aug_range: None\n",
            "    random_crop: False\n",
            "    token_warmup_min: 1,\n",
            "    token_warmup_step: 0,\n",
            "    is_reg: False\n",
            "    class_tokens: living\n",
            "    caption_extension: .txt\n",
            "\n",
            "\n",
            "[Dataset 0]\n",
            "loading image sizes.\n",
            "make buckets\n",
            "min_bucket_reso and max_bucket_reso are ignored if bucket_no_upscale is set, because bucket reso is defined by image size automatically / bucket_no_upscaleが指定された場合は、bucketの解像度は画像サイズから自動計算されるため、min_bucket_resoとmax_bucket_resoは無視されます\n",
            "number of images (including repeats)\n",
            "bucket 0: resolution (512, 512), count: 1600\n",
            "mean ar error (without repeats): 0.0\n",
            "preparing accelerator\n",
            "loading model for process 0/1\n",
            "load Diffusers pretrained models: runwayml/stable-diffusion-v1-5\n",
            "UNet2DConditionModel: 64, 8, 768, False, False\n",
            "U-Net converted to original U-Net\n",
            "import network module: networks.lora\n",
            "[Dataset 0]\n",
            "caching latents.\n",
            "checking cache validity...\n",
            "caching latents...\n",
            "create LoRA network. base dim (rank): 8, alpha: 1.0\n",
            "create LoRA for Text Encoder: 72 modules.\n",
            "create LoRA for U-Net: 192 modules.\n",
            "enable LoRA for text encoder\n",
            "enable LoRA for U-Net\n",
            "prepare optimizer, data loader etc.\n",
            "\n",
            "===================================BUG REPORT===================================\n",
            "Welcome to bitsandbytes. For bug reports, please submit your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n",
            "================================================================================\n",
            "binary_path: c:\\users\\jackchua\\miniconda3\\envs\\room\\lib\\site-packages\\bitsandbytes\\cuda_setup\\libbitsandbytes_cuda116.dll\n",
            "CUDA SETUP: Loading binary c:\\users\\jackchua\\miniconda3\\envs\\room\\lib\\site-packages\\bitsandbytes\\cuda_setup\\libbitsandbytes_cuda116.dll...\n",
            "use 8-bit AdamW optimizer | {}\n",
            "running training\n",
            "  num train images * repeats: 1600\n",
            "  num batches per epoch: 1600\n",
            "  num epochs: 1\n",
            "  batch size per device: 1\n",
            "  gradient accumulation steps 4\n",
            "  total optimization steps: 400\n",
            "\n",
            "epoch 1/1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  0%|          | 0/160 [00:00<?, ?it/s]\n",
            "100%|██████████| 160/160 [00:00<00:00, 4110.95it/s]\n",
            "text_encoder\\model.safetensors not found\n",
            "\n",
            "Loading pipeline components...:   0%|          | 0/5 [00:00<?, ?it/s]\n",
            "Loading pipeline components...:  60%|██████    | 3/5 [00:04<00:02,  1.44s/it]\n",
            "Loading pipeline components...:  80%|████████  | 4/5 [00:04<00:01,  1.10s/it]\n",
            "Loading pipeline components...: 100%|██████████| 5/5 [00:05<00:00,  1.01s/it]\n",
            "Loading pipeline components...: 100%|██████████| 5/5 [00:05<00:00,  1.10s/it]\n",
            "You have disabled the safety checker for <class 'diffusers.pipelines.stable_diffusion.pipeline_stable_diffusion.StableDiffusionPipeline'> by passing `safety_checker=None`. Ensure that you abide to the conditions of the Stable Diffusion license and do not expose unfiltered results in services or applications open to the public. Both the diffusers team and Hugging Face strongly recommend to keep the safety filter enabled in all public facing circumstances, disabling it only for use-cases that involve analyzing network behavior or auditing its results. For more information, please have a look at https://github.com/huggingface/diffusers/pull/254 .\n",
            "\n",
            "  0%|          | 0/160 [00:00<?, ?it/s]\n",
            "100%|██████████| 160/160 [00:00<?, ?it/s]\n",
            "\n",
            "  0%|          | 0/160 [00:00<?, ?it/s]\n",
            "  1%|          | 1/160 [00:06<18:32,  7.00s/it]\n",
            "  1%|▏         | 2/160 [00:07<00:35,  4.40it/s]\n",
            "  2%|▏         | 3/160 [00:07<00:37,  4.21it/s]\n",
            "  2%|▎         | 4/160 [00:07<00:36,  4.28it/s]\n",
            "  3%|▎         | 5/160 [00:07<00:36,  4.22it/s]\n",
            "  4%|▍         | 6/160 [00:08<00:36,  4.27it/s]\n",
            "  4%|▍         | 7/160 [00:08<00:35,  4.26it/s]\n",
            "  5%|▌         | 8/160 [00:08<00:35,  4.27it/s]\n",
            "  6%|▌         | 9/160 [00:08<00:35,  4.24it/s]\n",
            "  6%|▋         | 10/160 [00:09<00:36,  4.16it/s]\n",
            "  7%|▋         | 11/160 [00:09<00:35,  4.23it/s]\n",
            "  8%|▊         | 12/160 [00:09<00:34,  4.28it/s]\n",
            "  8%|▊         | 13/160 [00:09<00:34,  4.24it/s]\n",
            "  9%|▉         | 14/160 [00:10<00:34,  4.22it/s]\n",
            "  9%|▉         | 15/160 [00:10<00:34,  4.15it/s]\n",
            " 10%|█         | 16/160 [00:10<00:33,  4.24it/s]\n",
            " 11%|█         | 17/160 [00:10<00:33,  4.28it/s]\n",
            " 11%|█▏        | 18/160 [00:10<00:33,  4.25it/s]\n",
            " 12%|█▏        | 19/160 [00:11<00:33,  4.19it/s]\n",
            " 12%|█▎        | 20/160 [00:11<00:33,  4.23it/s]\n",
            " 13%|█▎        | 21/160 [00:11<00:32,  4.26it/s]\n",
            " 14%|█▍        | 22/160 [00:11<00:32,  4.20it/s]\n",
            " 14%|█▍        | 23/160 [00:12<00:32,  4.26it/s]\n",
            " 15%|█▌        | 24/160 [00:12<00:31,  4.27it/s]\n",
            " 16%|█▌        | 25/160 [00:12<00:32,  4.11it/s]\n",
            " 16%|█▋        | 26/160 [00:12<00:31,  4.25it/s]\n",
            " 17%|█▋        | 27/160 [00:13<00:31,  4.28it/s]\n",
            " 18%|█▊        | 28/160 [00:13<00:30,  4.29it/s]\n",
            " 18%|█▊        | 29/160 [00:13<00:30,  4.30it/s]\n",
            " 19%|█▉        | 30/160 [00:13<00:30,  4.21it/s]\n",
            " 19%|█▉        | 31/160 [00:14<00:30,  4.25it/s]\n",
            " 20%|██        | 32/160 [00:14<00:30,  4.22it/s]\n",
            " 21%|██        | 33/160 [00:14<00:30,  4.23it/s]\n",
            " 21%|██▏       | 34/160 [00:14<00:30,  4.19it/s]\n",
            " 22%|██▏       | 35/160 [00:15<00:29,  4.27it/s]\n",
            " 22%|██▎       | 36/160 [00:15<00:29,  4.22it/s]\n",
            " 23%|██▎       | 37/160 [00:15<00:28,  4.26it/s]\n",
            " 24%|██▍       | 38/160 [00:15<00:28,  4.24it/s]\n",
            " 24%|██▍       | 39/160 [00:15<00:29,  4.16it/s]\n",
            " 25%|██▌       | 40/160 [00:16<00:28,  4.23it/s]\n",
            " 26%|██▌       | 41/160 [00:16<00:27,  4.29it/s]\n",
            " 26%|██▋       | 42/160 [00:16<00:27,  4.22it/s]\n",
            " 27%|██▋       | 43/160 [00:16<00:28,  4.16it/s]\n",
            " 28%|██▊       | 44/160 [00:17<00:27,  4.18it/s]\n",
            " 28%|██▊       | 45/160 [00:17<00:26,  4.31it/s]\n",
            " 29%|██▉       | 46/160 [00:17<00:27,  4.16it/s]\n",
            " 29%|██▉       | 47/160 [00:17<00:26,  4.23it/s]\n",
            " 30%|███       | 48/160 [00:18<00:26,  4.20it/s]\n",
            " 31%|███       | 49/160 [00:18<00:26,  4.23it/s]\n",
            " 31%|███▏      | 50/160 [00:18<00:26,  4.19it/s]\n",
            " 32%|███▏      | 51/160 [00:18<00:25,  4.23it/s]\n",
            " 32%|███▎      | 52/160 [00:19<00:25,  4.27it/s]\n",
            " 33%|███▎      | 53/160 [00:19<00:25,  4.22it/s]\n",
            " 34%|███▍      | 54/160 [00:19<00:25,  4.20it/s]\n",
            " 34%|███▍      | 55/160 [00:19<00:25,  4.19it/s]\n",
            " 35%|███▌      | 56/160 [00:19<00:24,  4.23it/s]\n",
            " 36%|███▌      | 57/160 [00:20<00:23,  4.31it/s]\n",
            " 36%|███▋      | 58/160 [00:20<00:23,  4.30it/s]\n",
            " 37%|███▋      | 59/160 [00:20<00:24,  4.15it/s]\n",
            " 38%|███▊      | 60/160 [00:20<00:24,  4.16it/s]\n",
            " 38%|███▊      | 61/160 [00:21<00:23,  4.21it/s]\n",
            " 39%|███▉      | 62/160 [00:21<00:23,  4.21it/s]\n",
            " 39%|███▉      | 63/160 [00:21<00:22,  4.23it/s]\n",
            " 40%|████      | 64/160 [00:21<00:22,  4.33it/s]\n",
            " 41%|████      | 65/160 [00:22<00:22,  4.20it/s]\n",
            " 41%|████▏     | 66/160 [00:22<00:22,  4.27it/s]\n",
            " 42%|████▏     | 67/160 [00:22<00:22,  4.15it/s]\n",
            " 42%|████▎     | 68/160 [00:22<00:21,  4.21it/s]\n",
            " 43%|████▎     | 69/160 [00:23<00:21,  4.15it/s]\n",
            " 44%|████▍     | 70/160 [00:23<00:20,  4.31it/s]\n",
            " 44%|████▍     | 71/160 [00:23<00:21,  4.21it/s]\n",
            " 45%|████▌     | 72/160 [00:23<00:20,  4.25it/s]\n",
            " 46%|████▌     | 73/160 [00:24<00:20,  4.22it/s]\n",
            " 46%|████▋     | 74/160 [00:24<00:20,  4.27it/s]\n",
            " 47%|████▋     | 75/160 [00:24<00:19,  4.31it/s]\n",
            " 48%|████▊     | 76/160 [00:24<00:19,  4.20it/s]\n",
            " 48%|████▊     | 77/160 [00:24<00:20,  4.15it/s]\n",
            " 49%|████▉     | 78/160 [00:25<00:19,  4.26it/s]\n",
            " 49%|████▉     | 79/160 [00:25<00:19,  4.19it/s]\n",
            " 50%|█████     | 80/160 [00:25<00:18,  4.27it/s]\n",
            " 51%|█████     | 81/160 [00:25<00:18,  4.21it/s]\n",
            " 51%|█████▏    | 82/160 [00:26<00:18,  4.16it/s]\n",
            " 52%|█████▏    | 83/160 [00:26<00:18,  4.08it/s]\n",
            " 52%|█████▎    | 84/160 [00:26<00:18,  4.13it/s]\n",
            " 53%|█████▎    | 85/160 [00:26<00:17,  4.20it/s]\n",
            " 54%|█████▍    | 86/160 [00:27<00:17,  4.22it/s]\n",
            " 54%|█████▍    | 87/160 [00:27<00:17,  4.27it/s]\n",
            " 55%|█████▌    | 88/160 [00:27<00:17,  4.18it/s]\n",
            " 56%|█████▌    | 89/160 [00:27<00:16,  4.20it/s]\n",
            " 56%|█████▋    | 90/160 [00:28<00:16,  4.16it/s]\n",
            " 57%|█████▋    | 91/160 [00:28<00:16,  4.15it/s]\n",
            " 57%|█████▊    | 92/160 [00:28<00:16,  4.22it/s]\n",
            " 58%|█████▊    | 93/160 [00:28<00:16,  4.18it/s]\n",
            " 59%|█████▉    | 94/160 [00:29<00:15,  4.18it/s]\n",
            " 59%|█████▉    | 95/160 [00:29<00:15,  4.14it/s]\n",
            " 60%|██████    | 96/160 [00:29<00:15,  4.19it/s]\n",
            " 61%|██████    | 97/160 [00:29<00:14,  4.21it/s]\n",
            " 61%|██████▏   | 98/160 [00:29<00:14,  4.26it/s]\n",
            " 62%|██████▏   | 99/160 [00:30<00:14,  4.31it/s]\n",
            " 62%|██████▎   | 100/160 [00:30<00:14,  4.11it/s]\n",
            " 63%|██████▎   | 101/160 [00:30<00:14,  4.16it/s]\n",
            " 64%|██████▍   | 102/160 [00:30<00:13,  4.19it/s]\n",
            " 64%|██████▍   | 103/160 [00:31<00:13,  4.20it/s]\n",
            " 65%|██████▌   | 104/160 [00:31<00:13,  4.14it/s]\n",
            " 66%|██████▌   | 105/160 [00:31<00:12,  4.29it/s]\n",
            " 66%|██████▋   | 106/160 [00:31<00:12,  4.24it/s]\n",
            " 67%|██████▋   | 107/160 [00:32<00:12,  4.19it/s]\n",
            " 68%|██████▊   | 108/160 [00:32<00:12,  4.24it/s]\n",
            " 68%|██████▊   | 109/160 [00:32<00:12,  4.17it/s]\n",
            " 69%|██████▉   | 110/160 [00:32<00:11,  4.27it/s]\n",
            " 69%|██████▉   | 111/160 [00:33<00:11,  4.28it/s]\n",
            " 70%|███████   | 112/160 [00:33<00:11,  4.17it/s]\n",
            " 71%|███████   | 113/160 [00:33<00:11,  4.17it/s]\n",
            " 71%|███████▏  | 114/160 [00:33<00:11,  4.17it/s]\n",
            " 72%|███████▏  | 115/160 [00:34<00:10,  4.23it/s]\n",
            " 72%|███████▎  | 116/160 [00:34<00:10,  4.21it/s]\n",
            " 73%|███████▎  | 117/160 [00:34<00:10,  4.18it/s]\n",
            " 74%|███████▍  | 118/160 [00:34<00:09,  4.22it/s]\n",
            " 74%|███████▍  | 119/160 [00:34<00:09,  4.19it/s]\n",
            " 75%|███████▌  | 120/160 [00:35<00:09,  4.26it/s]\n",
            " 76%|███████▌  | 121/160 [00:35<00:09,  4.18it/s]\n",
            " 76%|███████▋  | 122/160 [00:35<00:08,  4.23it/s]\n",
            " 77%|███████▋  | 123/160 [00:35<00:08,  4.18it/s]\n",
            " 78%|███████▊  | 124/160 [00:36<00:08,  4.25it/s]\n",
            " 78%|███████▊  | 125/160 [00:36<00:08,  4.15it/s]\n",
            " 79%|███████▉  | 126/160 [00:36<00:08,  4.17it/s]\n",
            " 79%|███████▉  | 127/160 [00:36<00:07,  4.26it/s]\n",
            " 80%|████████  | 128/160 [00:37<00:07,  4.16it/s]\n",
            " 81%|████████  | 129/160 [00:37<00:07,  4.11it/s]\n",
            " 81%|████████▏ | 130/160 [00:37<00:07,  4.16it/s]\n",
            " 82%|████████▏ | 131/160 [00:37<00:06,  4.23it/s]\n",
            " 82%|████████▎ | 132/160 [00:38<00:06,  4.11it/s]\n",
            " 83%|████████▎ | 133/160 [00:38<00:06,  4.21it/s]\n",
            " 84%|████████▍ | 134/160 [00:38<00:06,  4.15it/s]\n",
            " 84%|████████▍ | 135/160 [00:38<00:06,  4.16it/s]\n",
            " 85%|████████▌ | 136/160 [00:39<00:05,  4.15it/s]\n",
            " 86%|████████▌ | 137/160 [00:39<00:05,  4.14it/s]\n",
            " 86%|████████▋ | 138/160 [00:39<00:05,  4.11it/s]\n",
            " 87%|████████▋ | 139/160 [00:39<00:05,  4.11it/s]\n",
            " 88%|████████▊ | 140/160 [00:39<00:04,  4.20it/s]\n",
            " 88%|████████▊ | 141/160 [00:40<00:04,  4.16it/s]\n",
            " 89%|████████▉ | 142/160 [00:40<00:04,  4.16it/s]\n",
            " 89%|████████▉ | 143/160 [00:40<00:04,  4.12it/s]\n",
            " 90%|█████████ | 144/160 [00:40<00:03,  4.15it/s]\n",
            " 91%|█████████ | 145/160 [00:41<00:03,  4.12it/s]\n",
            " 91%|█████████▏| 146/160 [00:41<00:03,  4.08it/s]\n",
            " 92%|█████████▏| 147/160 [00:41<00:03,  4.11it/s]\n",
            " 92%|█████████▎| 148/160 [00:41<00:02,  4.14it/s]\n",
            " 93%|█████████▎| 149/160 [00:42<00:02,  4.21it/s]\n",
            " 94%|█████████▍| 150/160 [00:42<00:02,  4.05it/s]\n",
            " 94%|█████████▍| 151/160 [00:42<00:02,  4.22it/s]\n",
            " 95%|█████████▌| 152/160 [00:42<00:01,  4.16it/s]\n",
            " 96%|█████████▌| 153/160 [00:43<00:01,  4.25it/s]\n",
            " 96%|█████████▋| 154/160 [00:43<00:01,  4.14it/s]\n",
            " 97%|█████████▋| 155/160 [00:43<00:01,  4.19it/s]\n",
            " 98%|█████████▊| 156/160 [00:43<00:00,  4.25it/s]\n",
            " 98%|█████████▊| 157/160 [00:44<00:00,  4.13it/s]\n",
            " 99%|█████████▉| 158/160 [00:44<00:00,  4.18it/s]\n",
            " 99%|█████████▉| 159/160 [00:44<00:00,  4.18it/s]\n",
            "100%|██████████| 160/160 [00:44<00:00,  4.17it/s]\n",
            "100%|██████████| 160/160 [00:44<00:00,  3.57it/s]\n",
            "\n",
            "steps:   0%|          | 0/400 [00:00<?, ?it/s]┌───────────────────── Traceback (most recent call last) ─────────────────────┐\n",
            "│ c:\\Users\\JackChua\\Projects\\NUS\\SEM02\\PRS-PM-2023-07-01-GRP5-roomifAI\\System │\n",
            "│ Code\\src\\main\\train_network.py:987 in <module>                              │\n",
            "│                                                                             │\n",
            "│   984 │   args = train_util.read_config_from_file(args, parser)             │\n",
            "│   985 │                                                                     │\n",
            "│   986 │   trainer = NetworkTrainer()                                        │\n",
            "│ > 987 │   trainer.train(args)                                               │\n",
            "│   988                                                                       │\n",
            "│                                                                             │\n",
            "│ c:\\Users\\JackChua\\Projects\\NUS\\SEM02\\PRS-PM-2023-07-01-GRP5-roomifAI\\System │\n",
            "│ Code\\src\\main\\train_network.py:772 in train                                 │\n",
            "│                                                                             │\n",
            "│   769 │   │   │   │   │                                                     │\n",
            "│   770 │   │   │   │   │   # Predict the noise residual                      │\n",
            "│   771 │   │   │   │   │   with accelerator.autocast():                      │\n",
            "│ > 772 │   │   │   │   │   │   noise_pred = self.call_unet(                  │\n",
            "│   773 │   │   │   │   │   │   │   args, accelerator, unet, noisy_latents, t │\n",
            "│   774 │   │   │   │   │   │   )                                             │\n",
            "│   775                                                                       │\n",
            "│                                                                             │\n",
            "│ c:\\Users\\JackChua\\Projects\\NUS\\SEM02\\PRS-PM-2023-07-01-GRP5-roomifAI\\System │\n",
            "│ Code\\src\\main\\train_network.py:124 in call_unet                             │\n",
            "│                                                                             │\n",
            "│   121 │   │   return encoder_hidden_states                                  │\n",
            "│   122 │                                                                     │\n",
            "│   123 │   def call_unet(self, args, accelerator, unet, noisy_latents, times │\n",
            "│ > 124 │   │   noise_pred = unet(noisy_latents, timesteps, text_conds).sampl │\n",
            "│   125 │   │   return noise_pred                                             │\n",
            "│   126 │                                                                     │\n",
            "│   127 │   def sample_images(self, accelerator, args, epoch, global_step, de │\n",
            "│                                                                             │\n",
            "│ c:\\users\\jackchua\\miniconda3\\envs\\room\\lib\\site-packages\\torch\\nn\\modules\\m │\n",
            "│ odule.py:1501 in _call_impl                                                 │\n",
            "│                                                                             │\n",
            "│   1498 │   │   if not (self._backward_hooks or self._backward_pre_hooks or  │\n",
            "│   1499 │   │   │   │   or _global_backward_pre_hooks or _global_backward_ho │\n",
            "│   1500 │   │   │   │   or _global_forward_hooks or _global_forward_pre_hook │\n",
            "│ > 1501 │   │   │   return forward_call(*args, **kwargs)                     │\n",
            "│   1502 │   │   # Do not call functions when jit is used                     │\n",
            "│   1503 │   │   full_backward_hooks, non_full_backward_hooks = [], []        │\n",
            "│   1504 │   │   backward_pre_hooks = []                                      │\n",
            "│                                                                             │\n",
            "│ c:\\users\\jackchua\\miniconda3\\envs\\room\\lib\\site-packages\\accelerate\\utils\\o │\n",
            "│ perations.py:495 in __call__                                                │\n",
            "│                                                                             │\n",
            "│   492 │   │   update_wrapper(self, model_forward)                           │\n",
            "│   493 │                                                                     │\n",
            "│   494 │   def __call__(self, *args, **kwargs):                              │\n",
            "│ > 495 │   │   return convert_to_fp32(self.model_forward(*args, **kwargs))   │\n",
            "│   496 │                                                                     │\n",
            "│   497 │   def __getstate__(self):                                           │\n",
            "│   498 │   │   raise pickle.PicklingError(                                   │\n",
            "│                                                                             │\n",
            "│ c:\\users\\jackchua\\miniconda3\\envs\\room\\lib\\site-packages\\torch\\amp\\autocast │\n",
            "│ _mode.py:14 in decorate_autocast                                            │\n",
            "│                                                                             │\n",
            "│    11 │   @functools.wraps(func)                                            │\n",
            "│    12 │   def decorate_autocast(*args, **kwargs):                           │\n",
            "│    13 │   │   with autocast_instance:                                       │\n",
            "│ >  14 │   │   │   return func(*args, **kwargs)                              │\n",
            "│    15 │   decorate_autocast.__script_unsupported = '@autocast() decorator i │\n",
            "│    16 │   return decorate_autocast                                          │\n",
            "│    17                                                                       │\n",
            "│                                                                             │\n",
            "│ c:\\Users\\JackChua\\Projects\\NUS\\SEM02\\PRS-PM-2023-07-01-GRP5-roomifAI\\System │\n",
            "│ Code\\src\\main\\library\\original_unet.py:1509 in forward                      │\n",
            "│                                                                             │\n",
            "│   1506 │   │   down_block_res_samples = (sample,)                           │\n",
            "│   1507 │   │   for downsample_block in self.down_blocks:                    │\n",
            "│   1508 │   │   │   if downsample_block.has_cross_attention:                 │\n",
            "│ > 1509 │   │   │   │   sample, res_samples = downsample_block(              │\n",
            "│   1510 │   │   │   │   │   hidden_states=sample,                            │\n",
            "│   1511 │   │   │   │   │   temb=emb,                                        │\n",
            "│   1512 │   │   │   │   │   encoder_hidden_states=encoder_hidden_states,     │\n",
            "│                                                                             │\n",
            "│ c:\\users\\jackchua\\miniconda3\\envs\\room\\lib\\site-packages\\torch\\nn\\modules\\m │\n",
            "│ odule.py:1501 in _call_impl                                                 │\n",
            "│                                                                             │\n",
            "│   1498 │   │   if not (self._backward_hooks or self._backward_pre_hooks or  │\n",
            "│   1499 │   │   │   │   or _global_backward_pre_hooks or _global_backward_ho │\n",
            "│   1500 │   │   │   │   or _global_forward_hooks or _global_forward_pre_hook │\n",
            "│ > 1501 │   │   │   return forward_call(*args, **kwargs)                     │\n",
            "│   1502 │   │   # Do not call functions when jit is used                     │\n",
            "│   1503 │   │   full_backward_hooks, non_full_backward_hooks = [], []        │\n",
            "│   1504 │   │   backward_pre_hooks = []                                      │\n",
            "│                                                                             │\n",
            "│ c:\\Users\\JackChua\\Projects\\NUS\\SEM02\\PRS-PM-2023-07-01-GRP5-roomifAI\\System │\n",
            "│ Code\\src\\main\\library\\original_unet.py:956 in forward                       │\n",
            "│                                                                             │\n",
            "│    953 │   │   │   │   )[0]                                                 │\n",
            "│    954 │   │   │   else:                                                    │\n",
            "│    955 │   │   │   │   hidden_states = resnet(hidden_states, temb)          │\n",
            "│ >  956 │   │   │   │   hidden_states = attn(hidden_states, encoder_hidden_s │\n",
            "│    957 │   │   │                                                            │\n",
            "│    958 │   │   │   output_states += (hidden_states,)                        │\n",
            "│    959                                                                      │\n",
            "│                                                                             │\n",
            "│ c:\\users\\jackchua\\miniconda3\\envs\\room\\lib\\site-packages\\torch\\nn\\modules\\m │\n",
            "│ odule.py:1501 in _call_impl                                                 │\n",
            "│                                                                             │\n",
            "│   1498 │   │   if not (self._backward_hooks or self._backward_pre_hooks or  │\n",
            "│   1499 │   │   │   │   or _global_backward_pre_hooks or _global_backward_ho │\n",
            "│   1500 │   │   │   │   or _global_forward_hooks or _global_forward_pre_hook │\n",
            "│ > 1501 │   │   │   return forward_call(*args, **kwargs)                     │\n",
            "│   1502 │   │   # Do not call functions when jit is used                     │\n",
            "│   1503 │   │   full_backward_hooks, non_full_backward_hooks = [], []        │\n",
            "│   1504 │   │   backward_pre_hooks = []                                      │\n",
            "│                                                                             │\n",
            "│ c:\\Users\\JackChua\\Projects\\NUS\\SEM02\\PRS-PM-2023-07-01-GRP5-roomifAI\\System │\n",
            "│ Code\\src\\main\\library\\original_unet.py:867 in forward                       │\n",
            "│                                                                             │\n",
            "│    864 │   │                                                                │\n",
            "│    865 │   │   # 2. Blocks                                                  │\n",
            "│    866 │   │   for block in self.transformer_blocks:                        │\n",
            "│ >  867 │   │   │   hidden_states = block(hidden_states, context=encoder_hid │\n",
            "│    868 │   │                                                                │\n",
            "│    869 │   │   # 3. Output                                                  │\n",
            "│    870 │   │   if not self.use_linear_projection:                           │\n",
            "│                                                                             │\n",
            "│ c:\\users\\jackchua\\miniconda3\\envs\\room\\lib\\site-packages\\torch\\nn\\modules\\m │\n",
            "│ odule.py:1501 in _call_impl                                                 │\n",
            "│                                                                             │\n",
            "│   1498 │   │   if not (self._backward_hooks or self._backward_pre_hooks or  │\n",
            "│   1499 │   │   │   │   or _global_backward_pre_hooks or _global_backward_ho │\n",
            "│   1500 │   │   │   │   or _global_forward_hooks or _global_forward_pre_hook │\n",
            "│ > 1501 │   │   │   return forward_call(*args, **kwargs)                     │\n",
            "│   1502 │   │   # Do not call functions when jit is used                     │\n",
            "│   1503 │   │   full_backward_hooks, non_full_backward_hooks = [], []        │\n",
            "│   1504 │   │   backward_pre_hooks = []                                      │\n",
            "│                                                                             │\n",
            "│ c:\\Users\\JackChua\\Projects\\NUS\\SEM02\\PRS-PM-2023-07-01-GRP5-roomifAI\\System │\n",
            "│ Code\\src\\main\\library\\original_unet.py:789 in forward                       │\n",
            "│                                                                             │\n",
            "│    786 │   │   # 1. Self-Attention                                          │\n",
            "│    787 │   │   norm_hidden_states = self.norm1(hidden_states)               │\n",
            "│    788 │   │                                                                │\n",
            "│ >  789 │   │   hidden_states = self.attn1(norm_hidden_states) + hidden_stat │\n",
            "│    790 │   │                                                                │\n",
            "│    791 │   │   # 2. Cross-Attention                                         │\n",
            "│    792 │   │   norm_hidden_states = self.norm2(hidden_states)               │\n",
            "│                                                                             │\n",
            "│ c:\\users\\jackchua\\miniconda3\\envs\\room\\lib\\site-packages\\torch\\nn\\modules\\m │\n",
            "│ odule.py:1501 in _call_impl                                                 │\n",
            "│                                                                             │\n",
            "│   1498 │   │   if not (self._backward_hooks or self._backward_pre_hooks or  │\n",
            "│   1499 │   │   │   │   or _global_backward_pre_hooks or _global_backward_ho │\n",
            "│   1500 │   │   │   │   or _global_forward_hooks or _global_forward_pre_hook │\n",
            "│ > 1501 │   │   │   return forward_call(*args, **kwargs)                     │\n",
            "│   1502 │   │   # Do not call functions when jit is used                     │\n",
            "│   1503 │   │   full_backward_hooks, non_full_backward_hooks = [], []        │\n",
            "│   1504 │   │   backward_pre_hooks = []                                      │\n",
            "│                                                                             │\n",
            "│ c:\\Users\\JackChua\\Projects\\NUS\\SEM02\\PRS-PM-2023-07-01-GRP5-roomifAI\\System │\n",
            "│ Code\\src\\main\\library\\original_unet.py:602 in forward                       │\n",
            "│                                                                             │\n",
            "│    599 │   │   key = self.reshape_heads_to_batch_dim(key)                   │\n",
            "│    600 │   │   value = self.reshape_heads_to_batch_dim(value)               │\n",
            "│    601 │   │                                                                │\n",
            "│ >  602 │   │   hidden_states = self._attention(query, key, value)           │\n",
            "│    603 │   │                                                                │\n",
            "│    604 │   │   # linear proj                                                │\n",
            "│    605 │   │   hidden_states = self.to_out[0](hidden_states)                │\n",
            "│                                                                             │\n",
            "│ c:\\Users\\JackChua\\Projects\\NUS\\SEM02\\PRS-PM-2023-07-01-GRP5-roomifAI\\System │\n",
            "│ Code\\src\\main\\library\\original_unet.py:624 in _attention                    │\n",
            "│                                                                             │\n",
            "│    621 │   │   attention_probs = attention_scores.softmax(dim=-1)           │\n",
            "│    622 │   │                                                                │\n",
            "│    623 │   │   # cast back to the original dtype                            │\n",
            "│ >  624 │   │   attention_probs = attention_probs.to(value.dtype)            │\n",
            "│    625 │   │                                                                │\n",
            "│    626 │   │   # compute attention output                                   │\n",
            "│    627 │   │   hidden_states = torch.bmm(attention_probs, value)            │\n",
            "└─────────────────────────────────────────────────────────────────────────────┘\n",
            "OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB (GPU 0; 4.00\n",
            "GiB total capacity; 3.10 GiB already allocated; 0 bytes free; 3.22 GiB reserved\n",
            "in total by PyTorch) If reserved memory is >> allocated memory try setting \n",
            "max_split_size_mb to avoid fragmentation.  See documentation for Memory \n",
            "Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "\n",
            "steps:   0%|          | 0/400 [00:01<?, ?it/s]\n",
            "┌───────────────────── Traceback (most recent call last) ─────────────────────┐\n",
            "│ c:\\users\\jackchua\\miniconda3\\envs\\room\\lib\\runpy.py:197 in                  │\n",
            "│ _run_module_as_main                                                         │\n",
            "│                                                                             │\n",
            "│   194 │   main_globals = sys.modules[\"__main__\"].__dict__                   │\n",
            "│   195 │   if alter_argv:                                                    │\n",
            "│   196 │   │   sys.argv[0] = mod_spec.origin                                 │\n",
            "│ > 197 │   return _run_code(code, main_globals, None,                        │\n",
            "│   198 │   │   │   │   │    \"__main__\", mod_spec)                            │\n",
            "│   199                                                                       │\n",
            "│   200 def run_module(mod_name, init_globals=None,                           │\n",
            "│                                                                             │\n",
            "│ c:\\users\\jackchua\\miniconda3\\envs\\room\\lib\\runpy.py:87 in _run_code         │\n",
            "│                                                                             │\n",
            "│    84 │   │   │   │   │      __loader__ = loader,                           │\n",
            "│    85 │   │   │   │   │      __package__ = pkg_name,                        │\n",
            "│    86 │   │   │   │   │      __spec__ = mod_spec)                           │\n",
            "│ >  87 │   exec(code, run_globals)                                           │\n",
            "│    88 │   return run_globals                                                │\n",
            "│    89                                                                       │\n",
            "│    90 def _run_module_code(code, init_globals=None,                         │\n",
            "│                                                                             │\n",
            "│ in <module>:7                                                               │\n",
            "│                                                                             │\n",
            "│   4 from accelerate.commands.accelerate_cli import main                     │\n",
            "│   5 if __name__ == '__main__':                                              │\n",
            "│   6 │   sys.argv[0] = re.sub(r'(-script\\.pyw|\\.exe)?$', '', sys.argv[0])    │\n",
            "│ > 7 │   sys.exit(main())                                                    │\n",
            "│   8                                                                         │\n",
            "│                                                                             │\n",
            "│ c:\\users\\jackchua\\miniconda3\\envs\\room\\lib\\site-packages\\accelerate\\command │\n",
            "│ s\\accelerate_cli.py:45 in main                                              │\n",
            "│                                                                             │\n",
            "│   42 │   │   exit(1)                                                        │\n",
            "│   43 │                                                                      │\n",
            "│   44 │   # Run                                                              │\n",
            "│ > 45 │   args.func(args)                                                    │\n",
            "│   46                                                                        │\n",
            "│   47                                                                        │\n",
            "│   48 if __name__ == \"__main__\":                                             │\n",
            "│                                                                             │\n",
            "│ c:\\users\\jackchua\\miniconda3\\envs\\room\\lib\\site-packages\\accelerate\\command │\n",
            "│ s\\launch.py:923 in launch_command                                           │\n",
            "│                                                                             │\n",
            "│   920 │   elif defaults is not None and defaults.compute_environment == Com │\n",
            "│   921 │   │   sagemaker_launcher(defaults, args)                            │\n",
            "│   922 │   else:                                                             │\n",
            "│ > 923 │   │   simple_launcher(args)                                         │\n",
            "│   924                                                                       │\n",
            "│   925                                                                       │\n",
            "│   926 def main():                                                           │\n",
            "│                                                                             │\n",
            "│ c:\\users\\jackchua\\miniconda3\\envs\\room\\lib\\site-packages\\accelerate\\command │\n",
            "│ s\\launch.py:579 in simple_launcher                                          │\n",
            "│                                                                             │\n",
            "│   576 │   process.wait()                                                    │\n",
            "│   577 │   if process.returncode != 0:                                       │\n",
            "│   578 │   │   if not args.quiet:                                            │\n",
            "│ > 579 │   │   │   raise subprocess.CalledProcessError(returncode=process.re │\n",
            "│   580 │   │   else:                                                         │\n",
            "│   581 │   │   │   sys.exit(1)                                               │\n",
            "│   582                                                                       │\n",
            "└─────────────────────────────────────────────────────────────────────────────┘\n",
            "CalledProcessError: Command \n",
            "'['c:\\\\users\\\\jackchua\\\\miniconda3\\\\envs\\\\room\\\\python.exe', \n",
            "'./train_network.py', '--enable_bucket', '--min_bucket_reso=256', \n",
            "'--max_bucket_reso=2048', \n",
            "'--pretrained_model_name_or_path=runwayml/stable-diffusion-v1-5', \n",
            "'--train_data_dir=./train/LoRA/train_data', '--resolution=512,512', \n",
            "'--output_dir=./train/LoRA/output', '--logging_dir=./train/LoRA/logs', \n",
            "'--network_alpha=1', '--save_model_as=safetensors', \n",
            "'--network_module=networks.lora', '--text_encoder_lr=5e-05', \n",
            "'--unet_lr=0.0001', '--network_dim=8', '--gradient_accumulation_steps=4', \n",
            "'--output_name=roomifai_living', '--lr_scheduler_num_cycles=1', \n",
            "'--no_half_vae', '--learning_rate=0.0001', '--lr_scheduler=cosine', \n",
            "'--lr_warmup_steps=40', '--train_batch_size=1', '--max_train_steps=400', \n",
            "'--save_every_n_epochs=1', '--mixed_precision=fp16', '--save_precision=fp16', \n",
            "'--caption_extension=.txt', '--cache_latents', '--optimizer_type=AdamW8bit', \n",
            "'--max_data_loader_n_workers=0', '--bucket_reso_steps=64', \n",
            "'--save_every_n_steps=100', '--bucket_no_upscale', '--noise_offset=0.0']' \n",
            "returned non-zero exit status 1.\n"
          ]
        }
      ],
      "source": [
        "#@title ## Accelerate Training\n",
        "# If the process doesn't start automatically, paste the command in the terminal and run, e.g.:\n",
        "# Note: it is recommended that you train on high VRAM GPUs i.e. 16GB VRAM and above, otherwise you will encounter out of memory errors\n",
        "\n",
        "!accelerate launch --num_cpu_threads_per_process=2 \"./train_network.py\" --enable_bucket --min_bucket_reso=256 --max_bucket_reso=2048               --pretrained_model_name_or_path=\"runwayml/stable-diffusion-v1-5\"   --train_data_dir=\"./train/LoRA/train_data\" --resolution=\"512,512\"  --output_dir=\"./train/LoRA/output\" --logging_dir=\"./train/LoRA/logs\" --network_alpha=\"1\"       --save_model_as=safetensors --network_module=networks.lora --text_encoder_lr=5e-05     --unet_lr=0.0001 --network_dim=8 --gradient_accumulation_steps=4   --output_name=\"roomifai_living\" --lr_scheduler_num_cycles=\"1\" --no_half_vae            --learning_rate=\"0.0001\" --lr_scheduler=\"cosine\" --lr_warmup_steps=\"40\"                --train_batch_size=\"1\" --max_train_steps=\"400\" --save_every_n_epochs=\"1\"               --mixed_precision=\"fp16\" --save_precision=\"fp16\" --caption_extension=\".txt\"            --cache_latents --optimizer_type=\"AdamW8bit\" --max_data_loader_n_workers=\"0\"           --bucket_reso_steps=64 --save_every_n_steps=\"100\" --bucket_no_upscale --noise_offset=0.0  "
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.9.17 ('room')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.17"
    },
    "vscode": {
      "interpreter": {
        "hash": "33e8c653b61fcd30db27bb9bf153aa9abf8c95d57f0a0708ce05bf3f3ed84366"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
